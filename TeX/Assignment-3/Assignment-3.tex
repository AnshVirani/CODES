\documentclass{article}
\newcounter{rownumbers}
\newcommand\rownumber{\stepcounter{rownumbers}\arabic{rownumbers}}
%\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{amsmath,amsfonts,mathtools}
\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}

\graphicspath{ {C:\Users\harsh\OneDrive\Documents} }
\usepackage{geometry}
 \geometry{
 a4paper,
 total={210mm,297mm},
 left=20mm,
 right=20mm,
 top=-2mm,
 bottom=2mm,
 }
 
%\usepackage[margin=0.5in]{geometry}

\usepackage{amsmath,amssymb}
\usepackage{ifpdf}
%\usepackage{cite}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{mdwmath}
\usepackage{pdfpages}
\usepackage{mdwtab}
\usepackage{eqparbox}
\usepackage{parskip}
%\onecolumn
%\input{psfig}
\usepackage{color}
\usepackage{graphicx}
\setlength{\textheight}{23.5cm} \setlength{\topmargin}{-1.05cm}
\setlength{\textwidth}{6.5in} \setlength{\oddsidemargin}{-0.5cm}
\renewcommand{\baselinestretch}{1}
\pagenumbering{arabic}
\linespread{1.15}
\begin{document}
\textbf{
\begin{center}
{
\large{School of Engineering and Applied Science (SEAS), Ahmedabad University}\vspace{5mm}
}
\end{center}
%
\begin{center}
\large{Probability and Stochastic Processes (MAT277)\\ \vspace{4mm}
Homework Assignment-3\\\vspace{2mm}
Enrollment No: AU2140096 \hspace{4cm} Name: Ansh Virani }
\end{center}}
\vspace{2mm}


\vspace{10mm}

\begin{enumerate}
\item 
    Consider that Alice and Bob have no first girl child then they have \(k\) children as mentioned in the question. So, the probability for no girl child is \( \left(\cfrac{1}{2^k}\right)\).\\\\
    When they have one girl the probability is the complement of no girl child,\\
    \[
    \left(1 - \cfrac{1}{2^k}\right)
    \]
    The first \( i^{th} \) offspring are usually boys, that is to have at least \( i \geq 1 \) the probability is \( \cfrac{1}{2^i} \).\\
    Therefore, the predicted number of male children has increased as
    \[
    \sum_{i=1}^k \left(\cfrac{1}{2^i}\right) = \left(1 - \cfrac{1}{2^k}\right)
    \]
    \[
        \boxed{\therefore\ \textnormal{The expected number of female or male children is same that is } \left(1 - \cfrac{1}{2^k}\right).}
    \]
\newpage
\item 
\begin{enumerate}
    \item 
    \textbf{Maximizing the expected amount of money:}\\
    Given that the commodity sells for \$2 per ounce now, we have \$1000 to spend. \\
    Therefore, we can buy 
    \[ 
    \cfrac{1,000}{2} = 500 \text{ ounces}
    \]
    After one week, the price of the commodity can either increase to \$4 per ounce or decrease to \$1 per ounce. Both possibilities are equally likely.\\
    \begin{enumerate}
        \item If the price increases to \$4 per ounce:
        \begin{itemize}
            \item we have 500 ounces.
            \item Selling them at \$4 per ounce would give us \( 500 \times 4 = \$2,000. \)
        \end{itemize}
        \item If the price decreases to \$1 per ounce:
        \begin{itemize}
            \item we still have 500 ounces.
            \item Selling them at \$1 per ounce would give us \( 500 \times 1 = \$500. \)
        \end{itemize}
    \end{enumerate}
    Since both the scenarios are equally likely to occur, we calculate the expected value by taking the average of the possible outcomes:
    \[
        E [\text{Money at the end of the week}] = \cfrac{2,000 + 500}{2} = \$1,250
    \]
    \[
        \boxed{\therefore\ \textnormal{Our expected amount of the commodity at the end of the week will be \(\approx\) 1,250 ounces.}}
    \]
    \item \textbf{Maximizing the expected amount of the commodity at the end of the wek:}\\
    We should wait until the end of the week to buy because the price will either be \$1 or \$4 per ounce with equal probability.\\\\
    Therefore, calculating the expected price at the end of the week by taking average we get, \$2.50 per ounce.\\    
    With the given amount, we can buy
    \[
    \cfrac{1,000}{2.50} = 400 \text{ ounces}
    \]
    \[
        \boxed{\therefore\ \textnormal{Our expected amount of the commodity at the end of the week will be 400 ounces.}}
    \]
    Hence, if our objective is to maximize the expected amount of money, we should buy the commodity now and hold onto it.\\\\
    That strategy ensures us obtain the most commodity for your money, taking into account the uncertainty that can take place within the price fluctuations.\\
    \end{enumerate}

\newpage
\item 
    Let, the variable \( X \) denotes the player's winnings. The probability that the player wins their \( n^{th} \) game is given by \( \left(\cfrac{1}{2}\right)^n \).\\
    Calculating the Expectation:
        \begin{align*}
        E [X] &= \sum_{i=1}^{\infty} X P(X = X) \\\\
            &= \sum_{i=1}^{\infty} \left[2^n\cdot \left(\cfrac{1}{2}\right)^n\right] \\\\
            &= \sum_{i=1}^{\infty} (1) \\\\
            &= \infty
        \end{align*}
        \begin{enumerate}
            \item 
            No, I would not be pay \$1 million to play this game once.\\
            Considering the best case scenario: \$1 million to play once and you win in the first toss, you will take home a big amount \$2 million. But on the other hand, if you lose the bet, you will lose the invested amount.(\textit{Not a small amount})\\\\
            \textit{The fact \( E[X] = \infty \) is the expected value in the long run, not for one game.}\\
            \item 
            Yes, the expectation when considering a long run is indeed "something large," so we can expect the profit. Therefore, one can pay \$1 million for each game.
        \end{enumerate}

\newpage
\item 
    From the properties of expectation,    
    \[
        E[a] = a, \quad \text{here } a \text{ is a constant.}
    \]
    \[
        E[a - X] = a - E[X], \quad \text{here } X \text{ is a random variable.}
    \]
    Consider any constant function \( y \) as function of random variable \( X \) as below.
    \begin{align*}
        y = (X - E[X])^k \quad \ldots (1)
    \end{align*} 
    Expand R.H.S of eq.(1) using Binomial's expansion,
    \begin{align*}
        (X - E[X])^k 
        &= \binom{k}{0}X^k(-E[X])^0 + \binom{k}{1}X^{k-1}(-E[X])^1 + \ldots + \binom{k}{k}X^0(-E[X])^k \\
        &= X^k + (-E[X])^k - \binom{k}{1}X^{k-1}(E[X]) + \ldots + (-E[X])^k
    \end{align*}
    substituting these values in eq.(1),
    \begin{equation*}
        y - X^k = (E[X])^k - \binom{k}{1}X^{k-1}(E[X]) + \ldots + \binom{k}{k-1}X(-E[X])^{k-1} \hspace{20mm}\ldots (2)
    \end{equation*} 
    Apply expectation on both sides of eq.(2),
    \begin{equation*}
        E[y - X^k] = E\left[(E[X])^k - \binom{k}{1}X^{k-1}(E[X]) + \ldots + \binom{k}{k-1}X(-E[X])^{k-1}\right] \hspace{10mm}\ldots (3)
    \end{equation*}  
    On applying properties of expectation from the eq.(3), 
    \begin{equation*}
        E[X^k] = (E[X])^k - \binom{k}{1}E[X^{k-1}(E[X])] + \ldots + \binom{k}{k-1}E[X(-E[X])^{k-1}] \hspace{15mm}\ldots (4)
    \end{equation*}
    From the above eq.(4) it is interpreted that,
    \begin{equation*}
        (E[X^k]) > (E[X])^k
    \end{equation*}
    \textit{Hence, proved.}

\newpage
\item
    \begin{enumerate}
        \item
            It is given that the length of the streaks is
            \[ 
                k = \cfrac{\log_2 n + 1}{2} \text{ where } n \text{ is some power of 2.} 
            \]
            Consider the length of streaks be denoted by \( k \) and \( Y_i \) be that term of sequence of flips which 
            represents \( 1 \) whenever the streak of length \( k \) starts from the \( i \)-th flip.\\    
            The length of the streak will be \( k \) from the \( i \)-th flip if the flips \( Y_i's \) are all same for \( i = 1,\ldots,n-k+1 \).
            It follows that
            \[ 
                \sum_{i=1}^{n-k+1} Y_i
            \]
            will the total number of streaks of length \( k \).\\
            It is known by the linearity of expectations that
            \[
                E\left[\sum_{i=1}^n X_i\right] = \sum_{i=1}^n E[X_i].
            \]
            Therefore, the expected value is,
            \[
                E\left[\sum_{i=1}^{n-k+1} Y_i\right] = \sum_{i=1}^{n-k+1} E[Y_i].
            \]
            The objective is to prove that the expected number of streaks of length \( k \) given scenario of the streak of flips is \( \cfrac{\log_2 n + 1}{n} \) where \( n \) is some power of 2.\\
            Consider the length of streaks be denoted by \( k \) and \( Y_i \) be that term of sequence of flips which represents 1 whenever the streak of length \( k \) starts from the \( i \)-th flip.\\
            The length of the streak will be \( k \) from the \( i \)-th flip if the flips \( Y_i's \) are all same for \( i = 1,...,n-k+1 \). It follows that
            \[
                \sum_{i=1}^{n-k+1} Y_i
            \]
            will the total number of streaks of length \( k \).
            It is known by the linearity of expectations that
            \[
                E\left[\sum_{i=1}^{n-k+1} X_i\right] = \sum_{i=1}^{n-k+1} E[X_i].
            \]
            Therefore, the expected value is,
            \[
                E\left[\sum_{i=1}^{n-k+1} Y_i\right] = \sum_{i=1}^{n-k+1} E[Y_i] = \sum_{i=1}^{n-k+1} Pr(Y_i = 1).
            \]
            The \( Y_i \) will have value 1 if \( k-1 \) flips produce the same result as \( X_i \). Since the dealt coin is fair and flips are independent, the probability that \( Y_i \) is 1 will be
            \[
                Pr(Y_i = 1) = \left(\cfrac{1}{2}\right)^{k-1}.
            \]
            Hence, the value is,
            \[
                E\left[\sum_{i=1}^{n-k+1} Y_i\right] = \sum_{i=1}^{n-k+1} \left(\cfrac{1}{2}\right)^{k-1}.
            \]
            Substitute \( \log_2 n + 1 \) for \( k \) and simplify as follows:
            \[
                E\left[\sum_{i=1}^{n-k+1} Y_i\right] = \sum_{i=1}^{n-k+1} \left(\cfrac{1}{2}\right)^{\log_2 n} = \cfrac{n-k+1}{n}.
            \]
            Further simplify using integration,
            \[
                E\left[\sum_{i=1}^{n-k+1} Y_i\right] = \sum_{i=1}^{n-k+1} \cfrac{1}{n} = \cfrac{n-k+1}{n} = \cfrac{n - \log_2 n - 1 + 1}{n} = 1 - \cfrac{\log_2 n}{n}
            \]
            Since \(\cfrac{\log_2 n}{n}\) is of order 1, the expected number of streaks of order \(k\) is \(1 - O(1)\) with respect to \(n\).\\
            \textit{Hence, proved.}
    
        \item 
            The objective is to prove that
            \[
                Pr(\text{no streak of length at least } [\log_2 n - 2\log_2\log_2 n]) < \cfrac{1}{n}.
            \]            
            Let \(n\) be the number of terms in the sequence of flips and the length of streaks be denoted by \(k\).\\            
            If the terms of the sequence be grouped into distinct blocks of \(k\) consecutive flips, then there will be \(\cfrac{n}{k}\) such blocks.\\            
            Let \(E_1\) be the event that the sequence of \(n\) terms does not have any streaks of length \(k\) and \(E_2\) be the event that none of the blocks have a streak of length \(k\).\\
            It is easy to observe that \(E_1\) is possible if \(E_2\) holds, that is if none of the blocks have the streaks of length \(k\) then sequence will also not have any such streak.\\
            Therefore, \(Pr(E_1) \leq Pr(E_2)\).\\            
            Since the coin is fair and flips are independent, the probability that a block of \( k \) consecutive flips has a streak of length \( k \) will be \( \left(\cfrac{1}{2}\right)^{k-1} \). Therefore, the probability that a block does not have any streak of length \( k \) is \( 1 - \cfrac{1}{2^{k-1}} \).\\
            As there are \( \cfrac{n}{k} \) blocks,
            \[
                Pr(E_2) = \left(1 - \cfrac{1}{2^{k-1}}\right)^{\cfrac{n}{k}}.
            \]            
            Use the facts that \( k = 1 \leq \log_2 n - 2\log_2\log_2 n \), \( \cfrac{n}{k} \leq \cfrac{n}{\log_2 n} \), and \( 1 - x \leq e^{-x} \) to simplify the probability of \( E_2 \).            
            \[
                Pr(E_2) \leq \left(1 - \cfrac{1}{2^{(\log_2 n - 2\log_2\log_2 n)}}\right)^{\cfrac{n}{\log_2 n}}
            \]            
            \[
                = \left(\cfrac{\log_2^2 n}{n}\right)^{\cfrac{n}{\log_2 n}-1}
            \]            
            \[
                \leq \exp\left(-\cfrac{n}{\log_2 n}\left(\cfrac{\log_2^2 n}{n}\right)\right)
            \]            
            \[
                = \exp\left(-\log_2 n \left(\cfrac{\log_2 n}{n} \left(\log_2 n - 1\right)\right)\right)
            \]            
            \[
                Pr(E_2) = \exp\left(-\log_2 n \left(1 - \cfrac{\log_2 n}{n}\right)\right)
            \]            
            It is obtained that \( Pr(E_2) = \exp\left(-\log_2 n \left(1 - \cfrac{\log_2 n}{n}\right)\right) \).\\
            Simplify further using the properties of logarithmic function.
            \[
                Pr(E_2) = \exp\left(-\log_2 n \left(1 - \cfrac{\log_2 n}{n}\right)\right)
            \]
            \[
                \leq \exp\left(-\log_2 n \left(\cfrac{1}{\log_2 e}\right)\right)
            \]
            \[
                = \exp\left(\cfrac{\log_2 n}{\log_2 e}\right)
            \]
            \[
                = \exp(-\ln n)
            \]
            It follows that
            \[
                Pr(E_2) \leq \cfrac{1}{n}.
            \]
            Hence, it is proved that
            \[
                Pr(\text{no streak of length at least } [\log_2 n - 2\log_2 \log_2 n]) < \cfrac{1}{n}.
            \]
    \end{enumerate}

\newpage
\item 
    \begin{enumerate}
    \item 
        Let \(f\) be a convex function on the interval I. If \(x_1, x_2, \ldots, x_n \in I\) and \(\lambda_1, \lambda_2, \ldots, \lambda_n\) are non negative real numbers such that \(\sum_{i=1}^{n} \lambda_i = 1\), then
        \[
            f\left(\sum_{i=1}^{n} \lambda_i x_i\right) \leq \sum_{i=1}^{n} \lambda_i f(x_i).
        \]
        The case for \(n = 2\) is true by the definition of convex. Assume the relation holds for \(n\), then we have
        \begin{align*}
            f\left(\sum_{i=1}^{n+1} \lambda_i x_i\right) &= f\left(\sum_{i=1}^{n} \lambda_i x_i + \lambda_{n+1}x_{n+1}\right)
            = f\left(\lambda_{n+1}\cdot x_{n+1} + (1 - \lambda_{n+1}) \cfrac{1}{1 - \lambda_{n+1}}\sum_{i=1}^{n} \lambda_i x_i\right)\\
            &\leq \lambda_{n+1}\cdot f(x_{n+1}) + (1 - \lambda_{n+1})\cdot f\left(\cfrac{1}{1 - \lambda_{n+1}}\sum_{i=1}^{n} \lambda_i x_i\right)\\
            &= \lambda_{n+1}\cdot f(x_{n+1}) + (1 - \lambda_{n+1})\cdot f\left(\sum_{i=1}^{n} \cfrac{\lambda_i}{1 - \lambda_{n+1}}\cdot x_i\right)\\
            &\leq \lambda_{n+1}\cdot f(x_{n+1}) + (1 - \lambda_{n+1})\cdot \sum_{i=1}^{n} \cfrac{\lambda_i}{1 - \lambda_{n+1}}\cdot f(x_i)\\
            &= \sum_{i=1}^{n} \lambda_i\cdot f(x_i) + \lambda_{n+1}\cdot f(x_{n+1})\\
            &= \sum_{i=1}^{n+1} \lambda_i f(x_i).
        \end{align*} 
        \textit{Hence, by induction, the theorem is proven.}\\
    \item 
        
    \end{enumerate}
\end{enumerate}
\end{document}